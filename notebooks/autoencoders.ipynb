{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing as mp\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Layer, Conv2D, MaxPooling2D, Dense, Flatten, Input, Dropout, Conv2DTranspose, Reshape\n",
    "from tensorflow.keras.backend import random_normal\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 28709\n",
      "Validation: 3589\n",
      "Test: 3589\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = np.load('../FER_plus.npz', allow_pickle=True)\n",
    "\n",
    "# Unpack datasets\n",
    "X_train = data['xtrain'][:, np.newaxis].astype(np.float) * 1./255\n",
    "Y_train = data['ytrain']\n",
    "print('Train: {}'.format(X_train.shape[0]))\n",
    "\n",
    "X_val = data['xvalid'][:, np.newaxis].astype(np.float) * 1./255\n",
    "Y_val = data['yvalid']\n",
    "print('Validation: {}'.format(X_val.shape[0]))\n",
    "\n",
    "X_test = data['xtest'][:, np.newaxis].astype(np.float) * 1./255\n",
    "Y_test = data['ytest']\n",
    "print('Test: {}'.format(X_test.shape[0]))\n",
    "\n",
    "labels = data['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 48, 48, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 12, 12, 32)        9248      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                147488    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 7)                 231       \n",
      "=================================================================\n",
      "Total params: 161,767\n",
      "Trainable params: 161,767\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(48,48,1)))\n",
    "model.add(Conv2D(16, (3,3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D((2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer=Adam(), loss=CategoricalCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "773/773 [==============================] - 26s 34ms/step - loss: 1.2376 - accuracy: 0.5249 - val_loss: 1.2529 - val_accuracy: 0.5153\n",
      "Epoch 2/70\n",
      "773/773 [==============================] - 28s 37ms/step - loss: 1.2261 - accuracy: 0.5343 - val_loss: 1.2359 - val_accuracy: 0.5253\n",
      "Epoch 3/70\n",
      "773/773 [==============================] - 29s 37ms/step - loss: 1.2310 - accuracy: 0.5328 - val_loss: 1.2671 - val_accuracy: 0.5132\n",
      "Epoch 4/70\n",
      "773/773 [==============================] - 30s 39ms/step - loss: 1.2275 - accuracy: 0.5274 - val_loss: 1.2543 - val_accuracy: 0.5173\n",
      "Epoch 5/70\n",
      "773/773 [==============================] - 31s 40ms/step - loss: 1.2139 - accuracy: 0.5383 - val_loss: 1.2438 - val_accuracy: 0.5228\n",
      "Epoch 6/70\n",
      "773/773 [==============================] - 32s 41ms/step - loss: 1.2149 - accuracy: 0.5375 - val_loss: 1.2443 - val_accuracy: 0.5272\n",
      "Epoch 7/70\n",
      "773/773 [==============================] - 31s 40ms/step - loss: 1.2134 - accuracy: 0.5410 - val_loss: 1.2415 - val_accuracy: 0.5272\n",
      "Epoch 8/70\n",
      "773/773 [==============================] - 27s 35ms/step - loss: 1.2081 - accuracy: 0.5427 - val_loss: 1.2353 - val_accuracy: 0.5282\n",
      "Epoch 9/70\n",
      "773/773 [==============================] - 26s 34ms/step - loss: 1.1998 - accuracy: 0.5444 - val_loss: 1.2346 - val_accuracy: 0.5288\n",
      "Epoch 10/70\n",
      "773/773 [==============================] - 28s 36ms/step - loss: 1.2030 - accuracy: 0.5400 - val_loss: 1.2643 - val_accuracy: 0.5197\n",
      "Epoch 11/70\n",
      "773/773 [==============================] - 30s 39ms/step - loss: 1.1919 - accuracy: 0.5469 - val_loss: 1.2307 - val_accuracy: 0.5222\n",
      "Epoch 12/70\n",
      "773/773 [==============================] - 31s 40ms/step - loss: 1.1919 - accuracy: 0.5489 - val_loss: 1.2430 - val_accuracy: 0.5130\n",
      "Epoch 13/70\n",
      "773/773 [==============================] - 31s 40ms/step - loss: 1.1877 - accuracy: 0.5489 - val_loss: 1.2319 - val_accuracy: 0.5282\n",
      "Epoch 14/70\n",
      "773/773 [==============================] - 30s 39ms/step - loss: 1.1855 - accuracy: 0.5491 - val_loss: 1.2418 - val_accuracy: 0.5280\n",
      "Epoch 15/70\n",
      "773/773 [==============================] - 27s 35ms/step - loss: 1.1806 - accuracy: 0.5498 - val_loss: 1.2432 - val_accuracy: 0.5325\n",
      "Epoch 16/70\n",
      "773/773 [==============================] - 27s 35ms/step - loss: 1.1830 - accuracy: 0.5490 - val_loss: 1.2541 - val_accuracy: 0.5257\n",
      "Epoch 17/70\n",
      "773/773 [==============================] - 28s 36ms/step - loss: 1.1771 - accuracy: 0.5550 - val_loss: 1.2246 - val_accuracy: 0.5315\n",
      "Epoch 18/70\n",
      "773/773 [==============================] - 27s 35ms/step - loss: 1.1760 - accuracy: 0.5547 - val_loss: 1.2375 - val_accuracy: 0.5268\n",
      "Epoch 19/70\n",
      "773/773 [==============================] - 25s 32ms/step - loss: 1.1702 - accuracy: 0.5560 - val_loss: 1.2224 - val_accuracy: 0.5268\n",
      "Epoch 20/70\n",
      "773/773 [==============================] - 28s 36ms/step - loss: 1.1701 - accuracy: 0.5554 - val_loss: 1.2465 - val_accuracy: 0.5297\n",
      "Epoch 21/70\n",
      "773/773 [==============================] - 28s 36ms/step - loss: 1.1689 - accuracy: 0.5530 - val_loss: 1.2316 - val_accuracy: 0.5312\n",
      "Epoch 22/70\n",
      "773/773 [==============================] - 28s 37ms/step - loss: 1.1617 - accuracy: 0.5578 - val_loss: 1.2359 - val_accuracy: 0.5247\n",
      "Epoch 23/70\n",
      "773/773 [==============================] - 29s 37ms/step - loss: 1.1632 - accuracy: 0.5580 - val_loss: 1.2360 - val_accuracy: 0.5235\n",
      "Epoch 24/70\n",
      "773/773 [==============================] - 26s 34ms/step - loss: 1.1585 - accuracy: 0.5617 - val_loss: 1.2706 - val_accuracy: 0.5242\n",
      "Epoch 25/70\n",
      "773/773 [==============================] - 27s 35ms/step - loss: 1.1559 - accuracy: 0.5651 - val_loss: 1.2361 - val_accuracy: 0.5250\n",
      "Epoch 26/70\n",
      "773/773 [==============================] - 28s 36ms/step - loss: 1.1539 - accuracy: 0.5625 - val_loss: 1.2520 - val_accuracy: 0.5207\n",
      "Epoch 27/70\n",
      "773/773 [==============================] - 26s 34ms/step - loss: 1.1540 - accuracy: 0.5621 - val_loss: 1.2471 - val_accuracy: 0.5255\n",
      "Epoch 28/70\n",
      "773/773 [==============================] - 27s 35ms/step - loss: 1.1525 - accuracy: 0.5637 - val_loss: 1.2411 - val_accuracy: 0.5285\n",
      "Epoch 29/70\n",
      "773/773 [==============================] - 26s 34ms/step - loss: 1.1430 - accuracy: 0.5660 - val_loss: 1.2420 - val_accuracy: 0.5240\n",
      "Epoch 30/70\n",
      "773/773 [==============================] - 26s 33ms/step - loss: 1.1463 - accuracy: 0.5642 - val_loss: 1.2295 - val_accuracy: 0.5350\n",
      "Epoch 31/70\n",
      "773/773 [==============================] - 26s 33ms/step - loss: 1.1538 - accuracy: 0.5612 - val_loss: 1.2436 - val_accuracy: 0.5278\n",
      "Epoch 32/70\n",
      "773/773 [==============================] - 26s 34ms/step - loss: 1.1472 - accuracy: 0.5647 - val_loss: 1.2238 - val_accuracy: 0.5343\n",
      "Epoch 33/70\n",
      "773/773 [==============================] - 29s 38ms/step - loss: 1.1421 - accuracy: 0.5688 - val_loss: 1.2340 - val_accuracy: 0.5325\n",
      "Epoch 34/70\n",
      "773/773 [==============================] - 30s 38ms/step - loss: 1.1360 - accuracy: 0.5702 - val_loss: 1.2383 - val_accuracy: 0.5322\n",
      "Epoch 35/70\n",
      "773/773 [==============================] - 28s 36ms/step - loss: 1.1277 - accuracy: 0.5743 - val_loss: 1.2365 - val_accuracy: 0.5322\n",
      "Epoch 36/70\n",
      "773/773 [==============================] - 27s 35ms/step - loss: 1.1307 - accuracy: 0.5716 - val_loss: 1.2249 - val_accuracy: 0.5347\n",
      "Epoch 37/70\n",
      "773/773 [==============================] - 28s 37ms/step - loss: 1.1336 - accuracy: 0.5730 - val_loss: 1.2255 - val_accuracy: 0.5328\n",
      "Epoch 38/70\n",
      "773/773 [==============================] - 28s 36ms/step - loss: 1.1319 - accuracy: 0.5727 - val_loss: 1.2609 - val_accuracy: 0.5293\n",
      "Epoch 39/70\n",
      "773/773 [==============================] - 27s 35ms/step - loss: 1.1332 - accuracy: 0.5707 - val_loss: 1.2614 - val_accuracy: 0.5213\n",
      "Epoch 40/70\n",
      "773/773 [==============================] - 26s 33ms/step - loss: 1.1395 - accuracy: 0.5690 - val_loss: 1.2295 - val_accuracy: 0.5280\n",
      "Epoch 41/70\n",
      "773/773 [==============================] - 26s 34ms/step - loss: 1.1253 - accuracy: 0.5713 - val_loss: 1.2536 - val_accuracy: 0.5280\n",
      "Epoch 42/70\n",
      "773/773 [==============================] - 28s 37ms/step - loss: 1.1224 - accuracy: 0.5753 - val_loss: 1.2587 - val_accuracy: 0.5305\n",
      "Epoch 43/70\n",
      "773/773 [==============================] - 33s 42ms/step - loss: 1.1255 - accuracy: 0.5760 - val_loss: 1.2375 - val_accuracy: 0.5303\n",
      "Epoch 44/70\n",
      "773/773 [==============================] - 28s 36ms/step - loss: 1.1261 - accuracy: 0.5726 - val_loss: 1.2363 - val_accuracy: 0.5365\n",
      "Epoch 45/70\n",
      "773/773 [==============================] - 29s 37ms/step - loss: 1.1155 - accuracy: 0.5793 - val_loss: 1.2602 - val_accuracy: 0.5318\n",
      "Epoch 46/70\n",
      "773/773 [==============================] - 26s 34ms/step - loss: 1.1224 - accuracy: 0.5745 - val_loss: 1.2418 - val_accuracy: 0.5380\n",
      "Epoch 47/70\n",
      "773/773 [==============================] - 28s 36ms/step - loss: 1.1193 - accuracy: 0.5791 - val_loss: 1.2456 - val_accuracy: 0.5272\n",
      "Epoch 48/70\n",
      "773/773 [==============================] - 28s 36ms/step - loss: 1.1149 - accuracy: 0.5747 - val_loss: 1.2389 - val_accuracy: 0.5325\n",
      "Epoch 49/70\n",
      "773/773 [==============================] - 27s 35ms/step - loss: 1.1134 - accuracy: 0.5811 - val_loss: 1.2394 - val_accuracy: 0.5335\n",
      "Epoch 50/70\n",
      "773/773 [==============================] - 30s 39ms/step - loss: 1.1123 - accuracy: 0.5801 - val_loss: 1.2366 - val_accuracy: 0.5320\n",
      "Epoch 51/70\n",
      "773/773 [==============================] - 31s 40ms/step - loss: 1.1115 - accuracy: 0.5804 - val_loss: 1.2657 - val_accuracy: 0.5288\n",
      "Epoch 52/70\n",
      "773/773 [==============================] - 31s 40ms/step - loss: 1.1084 - accuracy: 0.5837 - val_loss: 1.2403 - val_accuracy: 0.5332\n",
      "Epoch 53/70\n",
      "773/773 [==============================] - 30s 39ms/step - loss: 1.1139 - accuracy: 0.5796 - val_loss: 1.2439 - val_accuracy: 0.5330\n",
      "Epoch 54/70\n",
      "773/773 [==============================] - 32s 42ms/step - loss: 1.1054 - accuracy: 0.5842 - val_loss: 1.2524 - val_accuracy: 0.5242\n",
      "Epoch 55/70\n",
      "773/773 [==============================] - 26s 34ms/step - loss: 1.1025 - accuracy: 0.5858 - val_loss: 1.2404 - val_accuracy: 0.5335\n",
      "Epoch 56/70\n",
      "773/773 [==============================] - 26s 34ms/step - loss: 1.1039 - accuracy: 0.5839 - val_loss: 1.2254 - val_accuracy: 0.5332\n",
      "Epoch 57/70\n",
      "773/773 [==============================] - 28s 36ms/step - loss: 1.1013 - accuracy: 0.5801 - val_loss: 1.2286 - val_accuracy: 0.5395\n",
      "Epoch 58/70\n",
      "773/773 [==============================] - 26s 34ms/step - loss: 1.1040 - accuracy: 0.5836 - val_loss: 1.2390 - val_accuracy: 0.5337\n",
      "Epoch 59/70\n",
      "773/773 [==============================] - 27s 35ms/step - loss: 1.1070 - accuracy: 0.5802 - val_loss: 1.2295 - val_accuracy: 0.5307\n",
      "Epoch 60/70\n",
      "773/773 [==============================] - 27s 35ms/step - loss: 1.1015 - accuracy: 0.5857 - val_loss: 1.2554 - val_accuracy: 0.5372\n",
      "Epoch 61/70\n",
      "773/773 [==============================] - 27s 35ms/step - loss: 1.0959 - accuracy: 0.5837 - val_loss: 1.2517 - val_accuracy: 0.5268\n",
      "Epoch 62/70\n",
      "773/773 [==============================] - 29s 38ms/step - loss: 1.1014 - accuracy: 0.5849 - val_loss: 1.2429 - val_accuracy: 0.5380\n",
      "Epoch 63/70\n",
      "773/773 [==============================] - 32s 42ms/step - loss: 1.0943 - accuracy: 0.5850 - val_loss: 1.2485 - val_accuracy: 0.5305\n",
      "Epoch 64/70\n",
      "773/773 [==============================] - 32s 41ms/step - loss: 1.0965 - accuracy: 0.5852 - val_loss: 1.2516 - val_accuracy: 0.5370\n",
      "Epoch 65/70\n",
      "773/773 [==============================] - 29s 37ms/step - loss: 1.0890 - accuracy: 0.5860 - val_loss: 1.2164 - val_accuracy: 0.5508\n",
      "Epoch 66/70\n",
      "773/773 [==============================] - 27s 34ms/step - loss: 1.0964 - accuracy: 0.5873 - val_loss: 1.2400 - val_accuracy: 0.5320\n",
      "Epoch 67/70\n",
      "773/773 [==============================] - 26s 34ms/step - loss: 1.0903 - accuracy: 0.5867 - val_loss: 1.2538 - val_accuracy: 0.5282\n",
      "Epoch 68/70\n",
      "773/773 [==============================] - 26s 33ms/step - loss: 1.0908 - accuracy: 0.5879 - val_loss: 1.2310 - val_accuracy: 0.5385\n",
      "Epoch 69/70\n",
      "773/773 [==============================] - 27s 35ms/step - loss: 1.0882 - accuracy: 0.5884 - val_loss: 1.2453 - val_accuracy: 0.5385\n",
      "Epoch 70/70\n",
      "773/773 [==============================] - 27s 35ms/step - loss: 1.0899 - accuracy: 0.5903 - val_loss: 1.2308 - val_accuracy: 0.5315\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f821863e940>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trained up to 100 epochs\n",
    "model.fit(train_generator, validation_data=val_generator, epochs=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_26 (Conv2D)           (None, 48, 48, 16)        160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 24, 24, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 24, 24, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_21 (MaxPooling (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 12, 12, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling (None, 6, 6, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_15 (Conv2DT (None, 12, 12, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_16 (Conv2DT (None, 24, 24, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_17 (Conv2DT (None, 48, 48, 16)        4624      \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 48, 48, 1)         145       \n",
      "=================================================================\n",
      "Total params: 83,457\n",
      "Trainable params: 83,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# TODO: Separate out the encoder and decoder so the encoder can be used\n",
    "# for downstream tasks\n",
    "\n",
    "autoencoder = Sequential()\n",
    "\n",
    "# Encoder\n",
    "autoencoder.add(Input(shape=(48,48,1)))\n",
    "autoencoder.add(Conv2D(16, (3,3), activation='relu', padding='same'))\n",
    "autoencoder.add(MaxPooling2D((2,2)))\n",
    "autoencoder.add(Conv2D(32, (3,3), activation='relu', padding='same'))\n",
    "autoencoder.add(MaxPooling2D((2,2)))\n",
    "autoencoder.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
    "autoencoder.add(MaxPooling2D(2,2))\n",
    "\n",
    "# Decoder\n",
    "autoencoder.add(Conv2DTranspose(64, (3,3), strides=(2,2), activation='relu', padding='same'))\n",
    "autoencoder.add(Conv2DTranspose(32, (3,3), strides=(2,2), activation='relu', padding='same'))\n",
    "autoencoder.add(Conv2DTranspose(16, (3,3), strides=(2,2), activation='relu', padding='same'))\n",
    "autoencoder.add(Conv2D(1, (3,3), activation='sigmoid', padding='same'))\n",
    "\n",
    "autoencoder.compile(optimizer=Adam(), loss=tf.keras.losses.mae)\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/45\n",
      "773/773 [==============================] - 44s 56ms/step - loss: 0.0466 - val_loss: 0.0464\n",
      "Epoch 2/45\n",
      "773/773 [==============================] - 44s 57ms/step - loss: 0.0455 - val_loss: 0.0455\n",
      "Epoch 3/45\n",
      "773/773 [==============================] - 46s 59ms/step - loss: 0.0444 - val_loss: 0.0440\n",
      "Epoch 4/45\n",
      "773/773 [==============================] - 47s 61ms/step - loss: 0.0436 - val_loss: 0.0441\n",
      "Epoch 5/45\n",
      "773/773 [==============================] - 43s 56ms/step - loss: 0.0429 - val_loss: 0.0425\n",
      "Epoch 6/45\n",
      "773/773 [==============================] - 44s 57ms/step - loss: 0.0423 - val_loss: 0.0418\n",
      "Epoch 7/45\n",
      "773/773 [==============================] - 44s 56ms/step - loss: 0.0417 - val_loss: 0.0415\n",
      "Epoch 8/45\n",
      "773/773 [==============================] - 46s 59ms/step - loss: 0.0413 - val_loss: 0.0411\n",
      "Epoch 9/45\n",
      "773/773 [==============================] - 45s 58ms/step - loss: 0.0408 - val_loss: 0.0417\n",
      "Epoch 10/45\n",
      "773/773 [==============================] - 43s 56ms/step - loss: 0.0404 - val_loss: 0.0400\n",
      "Epoch 11/45\n",
      "773/773 [==============================] - 45s 58ms/step - loss: 0.0401 - val_loss: 0.0398\n",
      "Epoch 12/45\n",
      "773/773 [==============================] - 43s 55ms/step - loss: 0.0396 - val_loss: 0.0406\n",
      "Epoch 13/45\n",
      "773/773 [==============================] - 47s 60ms/step - loss: 0.0394 - val_loss: 0.0390\n",
      "Epoch 14/45\n",
      "773/773 [==============================] - 46s 60ms/step - loss: 0.0391 - val_loss: 0.0391\n",
      "Epoch 15/45\n",
      "773/773 [==============================] - 43s 55ms/step - loss: 0.0388 - val_loss: 0.0391\n",
      "Epoch 16/45\n",
      "773/773 [==============================] - 44s 56ms/step - loss: 0.0386 - val_loss: 0.0383\n",
      "Epoch 17/45\n",
      "773/773 [==============================] - 43s 55ms/step - loss: 0.0383 - val_loss: 0.0383\n",
      "Epoch 18/45\n",
      "773/773 [==============================] - 46s 60ms/step - loss: 0.0381 - val_loss: 0.0380\n",
      "Epoch 19/45\n",
      "773/773 [==============================] - 49s 63ms/step - loss: 0.0379 - val_loss: 0.0386\n",
      "Epoch 20/45\n",
      "773/773 [==============================] - 50s 65ms/step - loss: 0.0377 - val_loss: 0.0377\n",
      "Epoch 21/45\n",
      "773/773 [==============================] - 49s 63ms/step - loss: 0.0375 - val_loss: 0.0373\n",
      "Epoch 22/45\n",
      "773/773 [==============================] - 50s 64ms/step - loss: 0.0372 - val_loss: 0.0373\n",
      "Epoch 23/45\n",
      "773/773 [==============================] - 48s 63ms/step - loss: 0.0372 - val_loss: 0.0371\n",
      "Epoch 24/45\n",
      "773/773 [==============================] - 44s 57ms/step - loss: 0.0370 - val_loss: 0.0370\n",
      "Epoch 25/45\n",
      "773/773 [==============================] - 46s 60ms/step - loss: 0.0368 - val_loss: 0.0374\n",
      "Epoch 26/45\n",
      "773/773 [==============================] - 46s 60ms/step - loss: 0.0366 - val_loss: 0.0365\n",
      "Epoch 27/45\n",
      "773/773 [==============================] - 44s 57ms/step - loss: 0.0366 - val_loss: 0.0365\n",
      "Epoch 28/45\n",
      "773/773 [==============================] - 42s 54ms/step - loss: 0.0364 - val_loss: 0.0368\n",
      "Epoch 29/45\n",
      "773/773 [==============================] - 42s 54ms/step - loss: 0.0363 - val_loss: 0.0365\n",
      "Epoch 30/45\n",
      "773/773 [==============================] - 40s 52ms/step - loss: 0.0362 - val_loss: 0.0363\n",
      "Epoch 31/45\n",
      "773/773 [==============================] - 41s 53ms/step - loss: 0.0360 - val_loss: 0.0362\n",
      "Epoch 32/45\n",
      "773/773 [==============================] - 41s 53ms/step - loss: 0.0359 - val_loss: 0.0361\n",
      "Epoch 33/45\n",
      "773/773 [==============================] - 41s 53ms/step - loss: 0.0358 - val_loss: 0.0357\n",
      "Epoch 34/45\n",
      "773/773 [==============================] - 41s 54ms/step - loss: 0.0357 - val_loss: 0.0359\n",
      "Epoch 35/45\n",
      "773/773 [==============================] - 41s 53ms/step - loss: 0.0356 - val_loss: 0.0358\n",
      "Epoch 36/45\n",
      "773/773 [==============================] - 41s 53ms/step - loss: 0.0355 - val_loss: 0.0356\n",
      "Epoch 37/45\n",
      "773/773 [==============================] - 41s 53ms/step - loss: 0.0354 - val_loss: 0.0354\n",
      "Epoch 38/45\n",
      "773/773 [==============================] - 41s 53ms/step - loss: 0.0352 - val_loss: 0.0357\n",
      "Epoch 39/45\n",
      "773/773 [==============================] - 41s 53ms/step - loss: 0.0352 - val_loss: 0.0355\n",
      "Epoch 40/45\n",
      "773/773 [==============================] - 42s 54ms/step - loss: 0.0351 - val_loss: 0.0361\n",
      "Epoch 41/45\n",
      "773/773 [==============================] - 41s 54ms/step - loss: 0.0350 - val_loss: 0.0351\n",
      "Epoch 42/45\n",
      "773/773 [==============================] - 41s 53ms/step - loss: 0.0349 - val_loss: 0.0350\n",
      "Epoch 43/45\n",
      "773/773 [==============================] - 44s 56ms/step - loss: 0.0349 - val_loss: 0.0349\n",
      "Epoch 44/45\n",
      "773/773 [==============================] - 43s 55ms/step - loss: 0.0347 - val_loss: 0.0348\n",
      "Epoch 45/45\n",
      "773/773 [==============================] - 47s 60ms/step - loss: 0.0347 - val_loss: 0.0346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8208a5b250>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trained up to 50 epochs\n",
    "autoencoder.fit(train_generator, validation_data=val_generator, epochs=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 48, 48, 1)\n",
      "(48, 48, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8208cb7f10>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(pred.shape)\n",
    "print(ex[0][0].shape)\n",
    "plt.imshow(ex[0][0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f81f95926a0>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pred[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VAE\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 48, 48, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 24, 24, 16)   160         encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling2D) (None, 12, 12, 16)   0           conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 6, 6, 32)     4640        max_pooling2d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_36 (MaxPooling2D) (None, 3, 3, 32)     0           conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 2, 2, 64)     18496       max_pooling2d_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_37 (MaxPooling2D) (None, 1, 1, 64)     0           conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 64)           0           max_pooling2d_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 100)          6500        flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 100)          6500        flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sampling_2 (Sampling)           (None, 100)          0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, 48, 48, 1)    292865      sampling_2[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Square_2 (TensorFlo [(None, 100)]        0           z_mean[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_4 (TensorFlowOp [(None, 100)]        0           z_log_var[0][0]                  \n",
      "                                                                 tf_op_layer_Square_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Exp_2 (TensorFlowOp [(None, 100)]        0           z_log_var[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_5 (TensorFlowOp [(None, 100)]        0           tf_op_layer_Sub_4[0][0]          \n",
      "                                                                 tf_op_layer_Exp_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_2 (TensorFlow [(None, 100)]        0           tf_op_layer_Sub_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_2 (TensorFlowO [()]                 0           tf_op_layer_AddV2_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_2 (TensorFlowOp [()]                 0           tf_op_layer_Mean_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_loss_2 (AddLoss)            ()                   0           tf_op_layer_Mul_2[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 329,161\n",
      "Trainable params: 329,161\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Functional API Version\n",
    "\n",
    "latent_dims = 100\n",
    "\n",
    "# Samples z given z_mean, z_log_var\n",
    "class Sampling(Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch_size = tf.shape(z_mean)[0]\n",
    "        latent_dims = tf.shape(z_mean)[1]\n",
    "        \n",
    "        # Reparameterization Trick\n",
    "        epsilon = random_normal(shape=(batch_size, latent_dims))\n",
    "        \n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "# Encoder\n",
    "input_img = Input(shape=(48,48,1), name='encoder_input')\n",
    "e = Conv2D(16, (3,3), strides=(2,2), activation='relu', padding='same')(input_img)\n",
    "e = MaxPooling2D((2,2))(e)\n",
    "e = Conv2D(32, (3,3), strides=(2,2), activation='relu', padding='same')(e)\n",
    "e = MaxPooling2D((2,2))(e)\n",
    "e = Conv2D(64, (3,3), strides=(2,2), activation='relu', padding='same')(e)\n",
    "e = MaxPooling2D((2,2))(e)\n",
    "e = Flatten()(e)\n",
    "z_mean = Dense(latent_dims, name='z_mean')(e)\n",
    "z_log_var = Dense(latent_dims, name='z_log_var')(e)\n",
    "z = Sampling()((z_mean, z_log_var))\n",
    "\n",
    "encoder = Model(inputs=input_img, outputs=z, name='encoder')\n",
    "\n",
    "# Decoder\n",
    "input_z = Input(shape=(latent_dims,), name='decoder_input')\n",
    "d = Dense(6*6*64, activation='relu')(input_z)\n",
    "d = Reshape(target_shape=(6,6,64))(d)\n",
    "d = Conv2DTranspose(64, (3,3), strides=(2,2), activation='relu', padding='same')(d)\n",
    "d = Conv2DTranspose(32, (3,3), strides=(2,2), activation='relu', padding='same')(d)\n",
    "d = Conv2DTranspose(16, (3,3), strides=(2,2), activation='relu', padding='same')(d)\n",
    "x = Conv2DTranspose(1, (3,3), activation='relu', padding='same')(d)\n",
    "\n",
    "decoder = Model(inputs=input_z, outputs=x, name='decoder')\n",
    "\n",
    "# VAE\n",
    "output_img = decoder(z)\n",
    "vae = Model(inputs=input_img, outputs=output_img, name='VAE')\n",
    "\n",
    "# Define ELBO Loss\n",
    "kl_loss = -0.5 * tf.reduce_mean(z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1)\n",
    "vae.add_loss(kl_loss)\n",
    "\n",
    "# MSE Loss\n",
    "# w = 24000 / 32 = 750\n",
    "def scaled_mse(y_true, y_pred, w=750):\n",
    "    return w * tf.keras.losses.mean_squared_error(y_true, y_pred)\n",
    "\n",
    "vae.compile(optimizer=Adam(), loss=scaled_mse, metrics=[scaled_mse])\n",
    "vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "773/773 [==============================] - 21s 28ms/step - loss: 8.5911 - scaled_mse: 7.5216 - val_loss: 9.4486 - val_scaled_mse: 8.3713\n",
      "Epoch 2/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.5690 - scaled_mse: 7.4984 - val_loss: 9.3557 - val_scaled_mse: 8.2946\n",
      "Epoch 3/100\n",
      "773/773 [==============================] - 20s 26ms/step - loss: 8.5622 - scaled_mse: 7.4929 - val_loss: 9.4091 - val_scaled_mse: 8.3351\n",
      "Epoch 4/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.5618 - scaled_mse: 7.4922 - val_loss: 9.3353 - val_scaled_mse: 8.2645\n",
      "Epoch 5/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.5564 - scaled_mse: 7.4871 - val_loss: 9.5332 - val_scaled_mse: 8.4790\n",
      "Epoch 6/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.5477 - scaled_mse: 7.4795 - val_loss: 9.3580 - val_scaled_mse: 8.2902\n",
      "Epoch 7/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.5481 - scaled_mse: 7.4801 - val_loss: 9.4223 - val_scaled_mse: 8.3456\n",
      "Epoch 8/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.5450 - scaled_mse: 7.4771 - val_loss: 9.3968 - val_scaled_mse: 8.3266\n",
      "Epoch 9/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.5408 - scaled_mse: 7.4724 - val_loss: 9.4428 - val_scaled_mse: 8.3723\n",
      "Epoch 10/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.5350 - scaled_mse: 7.4658 - val_loss: 9.4229 - val_scaled_mse: 8.3503\n",
      "Epoch 11/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.5264 - scaled_mse: 7.4579 - val_loss: 9.3620 - val_scaled_mse: 8.3057\n",
      "Epoch 12/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.5278 - scaled_mse: 7.4595 - val_loss: 9.4424 - val_scaled_mse: 8.3648\n",
      "Epoch 13/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.5213 - scaled_mse: 7.4530 - val_loss: 9.3304 - val_scaled_mse: 8.2736\n",
      "Epoch 14/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.5138 - scaled_mse: 7.4470 - val_loss: 9.3613 - val_scaled_mse: 8.2858\n",
      "Epoch 15/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.5203 - scaled_mse: 7.4523 - val_loss: 9.3504 - val_scaled_mse: 8.2869\n",
      "Epoch 16/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.5064 - scaled_mse: 7.4399 - val_loss: 9.4127 - val_scaled_mse: 8.3332\n",
      "Epoch 17/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.5090 - scaled_mse: 7.4423 - val_loss: 9.3701 - val_scaled_mse: 8.3060\n",
      "Epoch 18/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.4976 - scaled_mse: 7.4298 - val_loss: 9.3877 - val_scaled_mse: 8.3249\n",
      "Epoch 19/100\n",
      "773/773 [==============================] - 21s 28ms/step - loss: 8.4989 - scaled_mse: 7.4324 - val_loss: 9.3518 - val_scaled_mse: 8.2713\n",
      "Epoch 20/100\n",
      "773/773 [==============================] - 21s 28ms/step - loss: 8.4925 - scaled_mse: 7.4250 - val_loss: 9.3990 - val_scaled_mse: 8.3265\n",
      "Epoch 21/100\n",
      "773/773 [==============================] - 21s 28ms/step - loss: 8.4915 - scaled_mse: 7.4245 - val_loss: 9.3501 - val_scaled_mse: 8.2765\n",
      "Epoch 22/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.4830 - scaled_mse: 7.4159 - val_loss: 9.3202 - val_scaled_mse: 8.2499\n",
      "Epoch 23/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.4812 - scaled_mse: 7.4148 - val_loss: 9.3817 - val_scaled_mse: 8.3091\n",
      "Epoch 24/100\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 8.4763 - scaled_mse: 7.4099 - val_loss: 9.3723 - val_scaled_mse: 8.3127\n",
      "Epoch 25/100\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 8.4784 - scaled_mse: 7.4125 - val_loss: 9.4089 - val_scaled_mse: 8.3346\n",
      "Epoch 26/100\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 8.4716 - scaled_mse: 7.4045 - val_loss: 9.4620 - val_scaled_mse: 8.3815\n",
      "Epoch 27/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.4694 - scaled_mse: 7.4026 - val_loss: 9.3819 - val_scaled_mse: 8.3164\n",
      "Epoch 28/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.4660 - scaled_mse: 7.3993 - val_loss: 9.3565 - val_scaled_mse: 8.2802\n",
      "Epoch 29/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.4664 - scaled_mse: 7.4005 - val_loss: 9.4422 - val_scaled_mse: 8.3831\n",
      "Epoch 30/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.4552 - scaled_mse: 7.3894 - val_loss: 9.3456 - val_scaled_mse: 8.2821\n",
      "Epoch 31/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.4549 - scaled_mse: 7.3883 - val_loss: 9.3402 - val_scaled_mse: 8.2726\n",
      "Epoch 32/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.4608 - scaled_mse: 7.3943 - val_loss: 9.3608 - val_scaled_mse: 8.2928\n",
      "Epoch 33/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.4492 - scaled_mse: 7.3825 - val_loss: 9.3027 - val_scaled_mse: 8.2441\n",
      "Epoch 34/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.4501 - scaled_mse: 7.3832 - val_loss: 9.3332 - val_scaled_mse: 8.2633\n",
      "Epoch 35/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.4436 - scaled_mse: 7.3776 - val_loss: 9.4328 - val_scaled_mse: 8.3620\n",
      "Epoch 36/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.4362 - scaled_mse: 7.3692 - val_loss: 9.3765 - val_scaled_mse: 8.2965\n",
      "Epoch 37/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.4368 - scaled_mse: 7.3695 - val_loss: 9.3888 - val_scaled_mse: 8.3127\n",
      "Epoch 38/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.4317 - scaled_mse: 7.3649 - val_loss: 9.3891 - val_scaled_mse: 8.3276\n",
      "Epoch 39/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.4320 - scaled_mse: 7.3664 - val_loss: 9.3234 - val_scaled_mse: 8.2725\n",
      "Epoch 40/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.4217 - scaled_mse: 7.3564 - val_loss: 9.3585 - val_scaled_mse: 8.2871\n",
      "Epoch 41/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.4391 - scaled_mse: 7.3720 - val_loss: 9.3654 - val_scaled_mse: 8.2870\n",
      "Epoch 42/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.4267 - scaled_mse: 7.3603 - val_loss: 9.3505 - val_scaled_mse: 8.2870\n",
      "Epoch 43/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.4237 - scaled_mse: 7.3565 - val_loss: 9.3771 - val_scaled_mse: 8.3078\n",
      "Epoch 44/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.4224 - scaled_mse: 7.3560 - val_loss: 9.3239 - val_scaled_mse: 8.2592\n",
      "Epoch 45/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.4182 - scaled_mse: 7.3528 - val_loss: 9.3537 - val_scaled_mse: 8.2813\n",
      "Epoch 46/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.4129 - scaled_mse: 7.3465 - val_loss: 9.3704 - val_scaled_mse: 8.3154\n",
      "Epoch 47/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.4147 - scaled_mse: 7.3484 - val_loss: 9.4492 - val_scaled_mse: 8.3672\n",
      "Epoch 48/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.4157 - scaled_mse: 7.3494 - val_loss: 9.3991 - val_scaled_mse: 8.3345\n",
      "Epoch 49/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.4059 - scaled_mse: 7.3406 - val_loss: 9.3153 - val_scaled_mse: 8.2571\n",
      "Epoch 50/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.4079 - scaled_mse: 7.3414 - val_loss: 9.4392 - val_scaled_mse: 8.3739\n",
      "Epoch 51/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.4080 - scaled_mse: 7.3410 - val_loss: 9.4337 - val_scaled_mse: 8.3682\n",
      "Epoch 52/100\n",
      "773/773 [==============================] - 21s 28ms/step - loss: 8.3997 - scaled_mse: 7.3334 - val_loss: 9.3321 - val_scaled_mse: 8.2662\n",
      "Epoch 53/100\n",
      "773/773 [==============================] - 21s 28ms/step - loss: 8.4016 - scaled_mse: 7.3353 - val_loss: 9.3575 - val_scaled_mse: 8.2939\n",
      "Epoch 54/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.3980 - scaled_mse: 7.3315 - val_loss: 9.3599 - val_scaled_mse: 8.2966\n",
      "Epoch 55/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.3878 - scaled_mse: 7.3208 - val_loss: 9.2993 - val_scaled_mse: 8.2363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100\n",
      "773/773 [==============================] - 20s 26ms/step - loss: 8.3985 - scaled_mse: 7.3331 - val_loss: 9.3688 - val_scaled_mse: 8.3032\n",
      "Epoch 57/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.3911 - scaled_mse: 7.3253 - val_loss: 9.3850 - val_scaled_mse: 8.3208\n",
      "Epoch 58/100\n",
      "773/773 [==============================] - 20s 26ms/step - loss: 8.3839 - scaled_mse: 7.3182 - val_loss: 9.3788 - val_scaled_mse: 8.3159\n",
      "Epoch 59/100\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 8.3901 - scaled_mse: 7.3230 - val_loss: 9.4345 - val_scaled_mse: 8.3718\n",
      "Epoch 60/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.3848 - scaled_mse: 7.3193 - val_loss: 9.3463 - val_scaled_mse: 8.2819\n",
      "Epoch 61/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.3799 - scaled_mse: 7.3135 - val_loss: 9.3525 - val_scaled_mse: 8.2792\n",
      "Epoch 62/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.3887 - scaled_mse: 7.3216 - val_loss: 9.3946 - val_scaled_mse: 8.3141\n",
      "Epoch 63/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.3813 - scaled_mse: 7.3131 - val_loss: 9.3621 - val_scaled_mse: 8.2967\n",
      "Epoch 64/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.3737 - scaled_mse: 7.3069 - val_loss: 9.3442 - val_scaled_mse: 8.2934\n",
      "Epoch 65/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.3775 - scaled_mse: 7.3104 - val_loss: 9.3678 - val_scaled_mse: 8.2967\n",
      "Epoch 66/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.3760 - scaled_mse: 7.3093 - val_loss: 9.3469 - val_scaled_mse: 8.2800\n",
      "Epoch 67/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.3652 - scaled_mse: 7.2994 - val_loss: 9.3749 - val_scaled_mse: 8.3037\n",
      "Epoch 68/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.3710 - scaled_mse: 7.3033 - val_loss: 9.3525 - val_scaled_mse: 8.2902\n",
      "Epoch 69/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.3691 - scaled_mse: 7.3027 - val_loss: 9.3327 - val_scaled_mse: 8.2665\n",
      "Epoch 70/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.3744 - scaled_mse: 7.3069 - val_loss: 9.5176 - val_scaled_mse: 8.4594\n",
      "Epoch 71/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.3583 - scaled_mse: 7.2920 - val_loss: 9.3923 - val_scaled_mse: 8.3256\n",
      "Epoch 72/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.3602 - scaled_mse: 7.2925 - val_loss: 9.3159 - val_scaled_mse: 8.2567\n",
      "Epoch 73/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.3603 - scaled_mse: 7.2925 - val_loss: 9.4033 - val_scaled_mse: 8.3339\n",
      "Epoch 74/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.3534 - scaled_mse: 7.2870 - val_loss: 9.3474 - val_scaled_mse: 8.2863\n",
      "Epoch 75/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.3666 - scaled_mse: 7.2994 - val_loss: 9.3854 - val_scaled_mse: 8.3137\n",
      "Epoch 76/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.3561 - scaled_mse: 7.2886 - val_loss: 9.4985 - val_scaled_mse: 8.4442\n",
      "Epoch 77/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.3529 - scaled_mse: 7.2856 - val_loss: 9.3458 - val_scaled_mse: 8.2719\n",
      "Epoch 78/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.3475 - scaled_mse: 7.2821 - val_loss: 9.3638 - val_scaled_mse: 8.3057\n",
      "Epoch 79/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.3462 - scaled_mse: 7.2791 - val_loss: 9.3372 - val_scaled_mse: 8.2718\n",
      "Epoch 80/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.3528 - scaled_mse: 7.2869 - val_loss: 9.3379 - val_scaled_mse: 8.2734\n",
      "Epoch 81/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.3514 - scaled_mse: 7.2841 - val_loss: 9.3333 - val_scaled_mse: 8.2732\n",
      "Epoch 82/100\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 8.3498 - scaled_mse: 7.2831 - val_loss: 9.4013 - val_scaled_mse: 8.3427\n",
      "Epoch 83/100\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 8.3411 - scaled_mse: 7.2736 - val_loss: 9.3140 - val_scaled_mse: 8.2498\n",
      "Epoch 84/100\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 8.3395 - scaled_mse: 7.2736 - val_loss: 9.3268 - val_scaled_mse: 8.2568\n",
      "Epoch 85/100\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 8.3416 - scaled_mse: 7.2747 - val_loss: 9.3711 - val_scaled_mse: 8.3109\n",
      "Epoch 86/100\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 8.3430 - scaled_mse: 7.2759 - val_loss: 9.3687 - val_scaled_mse: 8.2997\n",
      "Epoch 87/100\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 8.3351 - scaled_mse: 7.2678 - val_loss: 9.3507 - val_scaled_mse: 8.2811\n",
      "Epoch 88/100\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 8.3352 - scaled_mse: 7.2677 - val_loss: 9.4024 - val_scaled_mse: 8.3383\n",
      "Epoch 89/100\n",
      "773/773 [==============================] - 21s 28ms/step - loss: 8.3362 - scaled_mse: 7.2700 - val_loss: 9.3486 - val_scaled_mse: 8.2925\n",
      "Epoch 90/100\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 8.3326 - scaled_mse: 7.2656 - val_loss: 9.3565 - val_scaled_mse: 8.3010\n",
      "Epoch 91/100\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 8.3298 - scaled_mse: 7.2623 - val_loss: 9.3271 - val_scaled_mse: 8.2703\n",
      "Epoch 92/100\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 8.3227 - scaled_mse: 7.2567 - val_loss: 9.3455 - val_scaled_mse: 8.2735\n",
      "Epoch 93/100\n",
      "773/773 [==============================] - 21s 28ms/step - loss: 8.3277 - scaled_mse: 7.2604 - val_loss: 9.3569 - val_scaled_mse: 8.2899\n",
      "Epoch 94/100\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 8.3274 - scaled_mse: 7.2592 - val_loss: 9.3598 - val_scaled_mse: 8.2932\n",
      "Epoch 95/100\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 8.3279 - scaled_mse: 7.2605 - val_loss: 9.4703 - val_scaled_mse: 8.4058\n",
      "Epoch 96/100\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 8.3222 - scaled_mse: 7.2567 - val_loss: 9.3916 - val_scaled_mse: 8.3236\n",
      "Epoch 97/100\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 8.3202 - scaled_mse: 7.2517 - val_loss: 9.3222 - val_scaled_mse: 8.2411\n",
      "Epoch 98/100\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 8.3199 - scaled_mse: 7.2533 - val_loss: 9.3150 - val_scaled_mse: 8.2479\n",
      "Epoch 99/100\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 8.3199 - scaled_mse: 7.2521 - val_loss: 9.4090 - val_scaled_mse: 8.3435\n",
      "Epoch 100/100\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 8.3156 - scaled_mse: 7.2481 - val_loss: 9.4894 - val_scaled_mse: 8.4263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f81eaeff4f0>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trained up to 200\n",
    "vae.fit(train_generator, validation_data=val_generator, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = vae.predict(ex[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 48, 48, 1)\n",
      "(48, 48, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f8188854970>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(pred.shape)\n",
    "print(ex[0][0].shape)\n",
    "plt.imshow(ex[0][], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f81887ab160>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(pred[7], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beta-VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"Beta-VAE\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 48, 48, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 24, 24, 16)   160         encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_41 (MaxPooling2D) (None, 12, 12, 16)   0           conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 6, 6, 32)     4640        max_pooling2d_41[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_42 (MaxPooling2D) (None, 3, 3, 32)     0           conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 2, 2, 64)     18496       max_pooling2d_42[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_43 (MaxPooling2D) (None, 1, 1, 64)     0           conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_7 (Flatten)             (None, 64)           0           max_pooling2d_43[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "z_mean (Dense)                  (None, 100)          6500        flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_log_var (Dense)               (None, 100)          6500        flatten_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "sampling_4 (Sampling)           (None, 100)          0           z_mean[0][0]                     \n",
      "                                                                 z_log_var[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, 48, 48, 1)    292865      sampling_4[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Square_4 (TensorFlo [(None, 100)]        0           z_mean[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_8 (TensorFlowOp [(None, 100)]        0           z_log_var[0][0]                  \n",
      "                                                                 tf_op_layer_Square_4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Exp_4 (TensorFlowOp [(None, 100)]        0           z_log_var[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Sub_9 (TensorFlowOp [(None, 100)]        0           tf_op_layer_Sub_8[0][0]          \n",
      "                                                                 tf_op_layer_Exp_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_AddV2_4 (TensorFlow [(None, 100)]        0           tf_op_layer_Sub_9[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mean_4 (TensorFlowO [()]                 0           tf_op_layer_AddV2_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_5 (TensorFlowOp [()]                 0           tf_op_layer_Mean_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Mul_6 (TensorFlowOp [()]                 0           tf_op_layer_Mul_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_loss_4 (AddLoss)            ()                   0           tf_op_layer_Mul_6[0][0]          \n",
      "==================================================================================================\n",
      "Total params: 329,161\n",
      "Trainable params: 329,161\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Functional API Version\n",
    "\n",
    "latent_dims = 100\n",
    "\n",
    "# Samples z given z_mean, z_log_var\n",
    "class Sampling(Layer):\n",
    "    def call(self, inputs):\n",
    "        z_mean, z_log_var = inputs\n",
    "        batch_size = tf.shape(z_mean)[0]\n",
    "        latent_dims = tf.shape(z_mean)[1]\n",
    "        \n",
    "        # Reparameterization Trick\n",
    "        epsilon = random_normal(shape=(batch_size, latent_dims))\n",
    "        \n",
    "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "# Encoder\n",
    "input_img = Input(shape=(48,48,1), name='encoder_input')\n",
    "e = Conv2D(16, (3,3), strides=(2,2), activation='relu', padding='same')(input_img)\n",
    "e = MaxPooling2D((2,2))(e)\n",
    "e = Conv2D(32, (3,3), strides=(2,2), activation='relu', padding='same')(e)\n",
    "e = MaxPooling2D((2,2))(e)\n",
    "e = Conv2D(64, (3,3), strides=(2,2), activation='relu', padding='same')(e)\n",
    "e = MaxPooling2D((2,2))(e)\n",
    "e = Flatten()(e)\n",
    "z_mean = Dense(latent_dims, name='z_mean')(e)\n",
    "z_log_var = Dense(latent_dims, name='z_log_var')(e)\n",
    "z = Sampling()((z_mean, z_log_var))\n",
    "\n",
    "beta_encoder = Model(inputs=input_img, outputs=z, name='encoder')\n",
    "\n",
    "# Decoder\n",
    "input_z = Input(shape=(latent_dims,), name='decoder_input')\n",
    "d = Dense(6*6*64, activation='relu')(input_z)\n",
    "d = Reshape(target_shape=(6,6,64))(d)\n",
    "d = Conv2DTranspose(64, (3,3), strides=(2,2), activation='relu', padding='same')(d)\n",
    "d = Conv2DTranspose(32, (3,3), strides=(2,2), activation='relu', padding='same')(d)\n",
    "d = Conv2DTranspose(16, (3,3), strides=(2,2), activation='relu', padding='same')(d)\n",
    "x = Conv2DTranspose(1, (3,3), activation='relu', padding='same')(d)\n",
    "\n",
    "beta_decoder = Model(inputs=input_z, outputs=x, name='decoder')\n",
    "\n",
    "# VAE\n",
    "output_img = decoder(z)\n",
    "beta_vae = Model(inputs=input_img, outputs=output_img, name='Beta-VAE')\n",
    "\n",
    "# Define ELBO Loss (Where to add Beta? And how?)\n",
    "beta = 3\n",
    "kl_loss = -0.5 * tf.reduce_mean(z_log_var - tf.square(z_mean) - tf.exp(z_log_var) + 1) * beta\n",
    "beta_vae.add_loss(kl_loss)\n",
    "\n",
    "# MSE Loss\n",
    "# w = 24000 / 32 = 750\n",
    "def scaled_mse(y_true, y_pred, w=750):\n",
    "    return w * tf.keras.losses.mean_squared_error(y_true, y_pred)\n",
    "\n",
    "beta_vae.compile(optimizer=Adam(), loss=scaled_mse, metrics=[scaled_mse])\n",
    "beta_vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "773/773 [==============================] - 21s 28ms/step - loss: 24.1549 - scaled_mse: 22.7499 - val_loss: 18.3378 - val_scaled_mse: 16.8733\n",
      "Epoch 2/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 16.8891 - scaled_mse: 15.3681 - val_loss: 16.0828 - val_scaled_mse: 14.5392\n",
      "Epoch 3/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 15.3454 - scaled_mse: 13.7903 - val_loss: 14.8921 - val_scaled_mse: 13.3141\n",
      "Epoch 4/300\n",
      "773/773 [==============================] - 21s 28ms/step - loss: 14.4072 - scaled_mse: 12.8043 - val_loss: 14.2052 - val_scaled_mse: 12.5724\n",
      "Epoch 5/300\n",
      "773/773 [==============================] - 21s 28ms/step - loss: 13.8431 - scaled_mse: 12.2151 - val_loss: 13.8087 - val_scaled_mse: 12.1920\n",
      "Epoch 6/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 13.4582 - scaled_mse: 11.8144 - val_loss: 13.4934 - val_scaled_mse: 11.8006\n",
      "Epoch 7/300\n",
      "773/773 [==============================] - 20s 26ms/step - loss: 13.1549 - scaled_mse: 11.4915 - val_loss: 13.2869 - val_scaled_mse: 11.6245\n",
      "Epoch 8/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 12.9043 - scaled_mse: 11.2253 - val_loss: 13.0319 - val_scaled_mse: 11.3355\n",
      "Epoch 9/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 12.6793 - scaled_mse: 10.9762 - val_loss: 12.8242 - val_scaled_mse: 11.1188\n",
      "Epoch 10/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 12.4843 - scaled_mse: 10.7626 - val_loss: 12.6964 - val_scaled_mse: 10.9642\n",
      "Epoch 11/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 12.3199 - scaled_mse: 10.5829 - val_loss: 12.6389 - val_scaled_mse: 10.8677\n",
      "Epoch 12/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 12.1883 - scaled_mse: 10.4353 - val_loss: 12.3793 - val_scaled_mse: 10.6119\n",
      "Epoch 13/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 12.0661 - scaled_mse: 10.2964 - val_loss: 12.3147 - val_scaled_mse: 10.5410\n",
      "Epoch 14/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 11.9551 - scaled_mse: 10.1737 - val_loss: 12.2242 - val_scaled_mse: 10.4411\n",
      "Epoch 15/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 11.8484 - scaled_mse: 10.0517 - val_loss: 12.1102 - val_scaled_mse: 10.3403\n",
      "Epoch 16/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 11.7566 - scaled_mse: 9.9512 - val_loss: 12.0374 - val_scaled_mse: 10.2187\n",
      "Epoch 17/300\n",
      "773/773 [==============================] - 26s 34ms/step - loss: 11.6818 - scaled_mse: 9.8596 - val_loss: 11.9641 - val_scaled_mse: 10.1275\n",
      "Epoch 18/300\n",
      "773/773 [==============================] - 25s 32ms/step - loss: 11.6065 - scaled_mse: 9.7791 - val_loss: 12.0184 - val_scaled_mse: 10.1658\n",
      "Epoch 19/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 11.5307 - scaled_mse: 9.6905 - val_loss: 11.8661 - val_scaled_mse: 10.0225\n",
      "Epoch 20/300\n",
      "773/773 [==============================] - 20s 26ms/step - loss: 11.4642 - scaled_mse: 9.6163 - val_loss: 11.8046 - val_scaled_mse: 9.9327\n",
      "Epoch 21/300\n",
      "773/773 [==============================] - 20s 26ms/step - loss: 11.4089 - scaled_mse: 9.5525 - val_loss: 11.7664 - val_scaled_mse: 9.9349\n",
      "Epoch 22/300\n",
      "773/773 [==============================] - 20s 26ms/step - loss: 11.3348 - scaled_mse: 9.4743 - val_loss: 11.7651 - val_scaled_mse: 9.8925\n",
      "Epoch 23/300\n",
      "773/773 [==============================] - 20s 27ms/step - loss: 11.2942 - scaled_mse: 9.4222 - val_loss: 11.6488 - val_scaled_mse: 9.7944\n",
      "Epoch 24/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 11.2463 - scaled_mse: 9.3642 - val_loss: 11.6861 - val_scaled_mse: 9.8083\n",
      "Epoch 25/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 11.1997 - scaled_mse: 9.3085 - val_loss: 11.6266 - val_scaled_mse: 9.7213\n",
      "Epoch 26/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 11.1536 - scaled_mse: 9.2552 - val_loss: 11.6417 - val_scaled_mse: 9.7476\n",
      "Epoch 27/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 11.1084 - scaled_mse: 9.2016 - val_loss: 11.4978 - val_scaled_mse: 9.6031\n",
      "Epoch 28/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 11.0642 - scaled_mse: 9.1509 - val_loss: 11.5050 - val_scaled_mse: 9.5757\n",
      "Epoch 29/300\n",
      "773/773 [==============================] - 23s 29ms/step - loss: 11.0217 - scaled_mse: 9.0998 - val_loss: 11.5407 - val_scaled_mse: 9.5720\n",
      "Epoch 30/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 10.9981 - scaled_mse: 9.0668 - val_loss: 11.4117 - val_scaled_mse: 9.4911\n",
      "Epoch 31/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.9639 - scaled_mse: 9.0265 - val_loss: 11.4199 - val_scaled_mse: 9.4916\n",
      "Epoch 32/300\n",
      "773/773 [==============================] - 21s 28ms/step - loss: 10.9187 - scaled_mse: 8.9739 - val_loss: 11.4162 - val_scaled_mse: 9.4691\n",
      "Epoch 33/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.8889 - scaled_mse: 8.9368 - val_loss: 11.4121 - val_scaled_mse: 9.4786\n",
      "Epoch 34/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.8562 - scaled_mse: 8.9018 - val_loss: 11.3869 - val_scaled_mse: 9.4107\n",
      "Epoch 35/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.8283 - scaled_mse: 8.8680 - val_loss: 11.3947 - val_scaled_mse: 9.4293\n",
      "Epoch 36/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.8049 - scaled_mse: 8.8380 - val_loss: 11.3272 - val_scaled_mse: 9.3571\n",
      "Epoch 37/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.7748 - scaled_mse: 8.8038 - val_loss: 11.2922 - val_scaled_mse: 9.3195\n",
      "Epoch 38/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.7681 - scaled_mse: 8.7911 - val_loss: 11.2664 - val_scaled_mse: 9.2834\n",
      "Epoch 39/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.7296 - scaled_mse: 8.7510 - val_loss: 11.2196 - val_scaled_mse: 9.2652\n",
      "Epoch 40/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.7196 - scaled_mse: 8.7353 - val_loss: 11.2410 - val_scaled_mse: 9.3004\n",
      "Epoch 41/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.6886 - scaled_mse: 8.7014 - val_loss: 11.1882 - val_scaled_mse: 9.1996\n",
      "Epoch 42/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.6719 - scaled_mse: 8.6815 - val_loss: 11.3114 - val_scaled_mse: 9.3669\n",
      "Epoch 43/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.6511 - scaled_mse: 8.6588 - val_loss: 11.1840 - val_scaled_mse: 9.2122\n",
      "Epoch 44/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.6383 - scaled_mse: 8.6441 - val_loss: 11.1787 - val_scaled_mse: 9.1539\n",
      "Epoch 45/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.6108 - scaled_mse: 8.6124 - val_loss: 11.1849 - val_scaled_mse: 9.1979\n",
      "Epoch 46/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 10.6049 - scaled_mse: 8.6038 - val_loss: 11.2440 - val_scaled_mse: 9.2477\n",
      "Epoch 47/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.5814 - scaled_mse: 8.5788 - val_loss: 11.2107 - val_scaled_mse: 9.1972\n",
      "Epoch 48/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.5649 - scaled_mse: 8.5595 - val_loss: 11.1288 - val_scaled_mse: 9.1124\n",
      "Epoch 49/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.5594 - scaled_mse: 8.5483 - val_loss: 11.1865 - val_scaled_mse: 9.1918\n",
      "Epoch 50/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 10.5379 - scaled_mse: 8.5264 - val_loss: 11.1812 - val_scaled_mse: 9.1612\n",
      "Epoch 51/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 10.5301 - scaled_mse: 8.5148 - val_loss: 11.1011 - val_scaled_mse: 9.0893\n",
      "Epoch 52/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.5103 - scaled_mse: 8.4925 - val_loss: 11.0975 - val_scaled_mse: 9.0412\n",
      "Epoch 53/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.5003 - scaled_mse: 8.4789 - val_loss: 11.0824 - val_scaled_mse: 9.0649\n",
      "Epoch 54/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.4849 - scaled_mse: 8.4612 - val_loss: 11.1516 - val_scaled_mse: 9.1305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/300\n",
      "773/773 [==============================] - 20s 26ms/step - loss: 10.4731 - scaled_mse: 8.4464 - val_loss: 11.1270 - val_scaled_mse: 9.1162\n",
      "Epoch 56/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.4614 - scaled_mse: 8.4334 - val_loss: 11.1343 - val_scaled_mse: 9.1099\n",
      "Epoch 57/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.4406 - scaled_mse: 8.4105 - val_loss: 11.1018 - val_scaled_mse: 9.0879\n",
      "Epoch 58/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.4319 - scaled_mse: 8.4019 - val_loss: 11.0380 - val_scaled_mse: 9.0404\n",
      "Epoch 59/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.4264 - scaled_mse: 8.3934 - val_loss: 11.1139 - val_scaled_mse: 9.0869\n",
      "Epoch 60/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.4167 - scaled_mse: 8.3822 - val_loss: 11.0378 - val_scaled_mse: 9.0102\n",
      "Epoch 61/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.4067 - scaled_mse: 8.3667 - val_loss: 11.0589 - val_scaled_mse: 9.0482\n",
      "Epoch 62/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 10.4008 - scaled_mse: 8.3599 - val_loss: 11.0023 - val_scaled_mse: 8.9479\n",
      "Epoch 63/300\n",
      "773/773 [==============================] - 21s 28ms/step - loss: 10.3839 - scaled_mse: 8.3415 - val_loss: 11.0109 - val_scaled_mse: 8.9690\n",
      "Epoch 64/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 10.3857 - scaled_mse: 8.3392 - val_loss: 11.0049 - val_scaled_mse: 8.9680\n",
      "Epoch 65/300\n",
      "773/773 [==============================] - 21s 28ms/step - loss: 10.3675 - scaled_mse: 8.3209 - val_loss: 11.0442 - val_scaled_mse: 9.0013\n",
      "Epoch 66/300\n",
      "773/773 [==============================] - 21s 28ms/step - loss: 10.3626 - scaled_mse: 8.3166 - val_loss: 11.0497 - val_scaled_mse: 8.9658\n",
      "Epoch 67/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 10.3525 - scaled_mse: 8.3013 - val_loss: 10.9958 - val_scaled_mse: 8.9547\n",
      "Epoch 68/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 10.3409 - scaled_mse: 8.2903 - val_loss: 11.0024 - val_scaled_mse: 8.9340\n",
      "Epoch 69/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 10.3314 - scaled_mse: 8.2783 - val_loss: 10.9893 - val_scaled_mse: 8.9534\n",
      "Epoch 70/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 10.3247 - scaled_mse: 8.2681 - val_loss: 11.0156 - val_scaled_mse: 8.9784\n",
      "Epoch 71/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 10.3163 - scaled_mse: 8.2589 - val_loss: 10.9840 - val_scaled_mse: 8.9109\n",
      "Epoch 72/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 10.3035 - scaled_mse: 8.2440 - val_loss: 11.0966 - val_scaled_mse: 9.0529\n",
      "Epoch 73/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 10.3075 - scaled_mse: 8.2452 - val_loss: 10.9540 - val_scaled_mse: 8.9018\n",
      "Epoch 74/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 10.2909 - scaled_mse: 8.2258 - val_loss: 11.0049 - val_scaled_mse: 8.9510\n",
      "Epoch 75/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 10.2919 - scaled_mse: 8.2260 - val_loss: 10.9418 - val_scaled_mse: 8.8897\n",
      "Epoch 76/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 10.2856 - scaled_mse: 8.2206 - val_loss: 10.9302 - val_scaled_mse: 8.8680\n",
      "Epoch 77/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 10.2676 - scaled_mse: 8.1997 - val_loss: 10.9411 - val_scaled_mse: 8.8775\n",
      "Epoch 78/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 10.2668 - scaled_mse: 8.1987 - val_loss: 10.9729 - val_scaled_mse: 8.9053\n",
      "Epoch 79/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 10.2508 - scaled_mse: 8.1812 - val_loss: 10.9860 - val_scaled_mse: 8.9239\n",
      "Epoch 80/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 10.2603 - scaled_mse: 8.1849 - val_loss: 11.0627 - val_scaled_mse: 8.9568\n",
      "Epoch 81/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 10.2578 - scaled_mse: 8.1807 - val_loss: 10.9508 - val_scaled_mse: 8.8802\n",
      "Epoch 82/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 10.2479 - scaled_mse: 8.1710 - val_loss: 10.9294 - val_scaled_mse: 8.8732\n",
      "Epoch 83/300\n",
      "773/773 [==============================] - 21s 28ms/step - loss: 10.2387 - scaled_mse: 8.1595 - val_loss: 10.9389 - val_scaled_mse: 8.8555\n",
      "Epoch 84/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 10.2268 - scaled_mse: 8.1498 - val_loss: 11.1011 - val_scaled_mse: 9.0133\n",
      "Epoch 85/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 10.2239 - scaled_mse: 8.1448 - val_loss: 10.9302 - val_scaled_mse: 8.8265\n",
      "Epoch 86/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 10.2266 - scaled_mse: 8.1453 - val_loss: 10.9135 - val_scaled_mse: 8.8552\n",
      "Epoch 87/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 10.2115 - scaled_mse: 8.1300 - val_loss: 10.9681 - val_scaled_mse: 8.8925\n",
      "Epoch 88/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 10.2097 - scaled_mse: 8.1228 - val_loss: 10.9358 - val_scaled_mse: 8.8609\n",
      "Epoch 89/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 10.2011 - scaled_mse: 8.1136 - val_loss: 11.0944 - val_scaled_mse: 9.0453\n",
      "Epoch 90/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 10.2034 - scaled_mse: 8.1149 - val_loss: 11.0234 - val_scaled_mse: 8.9483\n",
      "Epoch 91/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.2045 - scaled_mse: 8.1174 - val_loss: 10.9033 - val_scaled_mse: 8.8045\n",
      "Epoch 92/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.1875 - scaled_mse: 8.1005 - val_loss: 10.9155 - val_scaled_mse: 8.8202\n",
      "Epoch 93/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.1882 - scaled_mse: 8.0971 - val_loss: 10.9942 - val_scaled_mse: 8.9276\n",
      "Epoch 94/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.1788 - scaled_mse: 8.0869 - val_loss: 10.9961 - val_scaled_mse: 8.9009\n",
      "Epoch 95/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.1796 - scaled_mse: 8.0887 - val_loss: 10.9050 - val_scaled_mse: 8.8243\n",
      "Epoch 96/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.1688 - scaled_mse: 8.0742 - val_loss: 10.9086 - val_scaled_mse: 8.8153\n",
      "Epoch 97/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.1689 - scaled_mse: 8.0723 - val_loss: 10.9060 - val_scaled_mse: 8.7883\n",
      "Epoch 98/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.1631 - scaled_mse: 8.0667 - val_loss: 10.8864 - val_scaled_mse: 8.7942\n",
      "Epoch 99/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 10.1529 - scaled_mse: 8.0547 - val_loss: 10.8725 - val_scaled_mse: 8.8079\n",
      "Epoch 100/300\n",
      "773/773 [==============================] - 21s 28ms/step - loss: 10.1623 - scaled_mse: 8.0606 - val_loss: 10.9283 - val_scaled_mse: 8.8525\n",
      "Epoch 101/300\n",
      "773/773 [==============================] - 21s 28ms/step - loss: 10.1411 - scaled_mse: 8.0391 - val_loss: 11.0021 - val_scaled_mse: 8.9238\n",
      "Epoch 102/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 10.1434 - scaled_mse: 8.0406 - val_loss: 10.8712 - val_scaled_mse: 8.7716\n",
      "Epoch 103/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 10.1474 - scaled_mse: 8.0426 - val_loss: 10.9580 - val_scaled_mse: 8.8641\n",
      "Epoch 104/300\n",
      "773/773 [==============================] - 21s 28ms/step - loss: 10.1350 - scaled_mse: 8.0299 - val_loss: 10.9044 - val_scaled_mse: 8.8525\n",
      "Epoch 105/300\n",
      "773/773 [==============================] - 21s 28ms/step - loss: 10.1297 - scaled_mse: 8.0244 - val_loss: 10.8570 - val_scaled_mse: 8.7643\n",
      "Epoch 106/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 10.1284 - scaled_mse: 8.0239 - val_loss: 10.8505 - val_scaled_mse: 8.7275\n",
      "Epoch 107/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 10.1226 - scaled_mse: 8.0153 - val_loss: 10.8859 - val_scaled_mse: 8.7849\n",
      "Epoch 108/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 10.1229 - scaled_mse: 8.0149 - val_loss: 10.8584 - val_scaled_mse: 8.7817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 109/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.1231 - scaled_mse: 8.0118 - val_loss: 10.8660 - val_scaled_mse: 8.7713\n",
      "Epoch 110/300\n",
      "773/773 [==============================] - 20s 26ms/step - loss: 10.1176 - scaled_mse: 8.0063 - val_loss: 10.8710 - val_scaled_mse: 8.7489\n",
      "Epoch 111/300\n",
      "773/773 [==============================] - 20s 26ms/step - loss: 10.1124 - scaled_mse: 8.0009 - val_loss: 10.8825 - val_scaled_mse: 8.7647\n",
      "Epoch 112/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.1072 - scaled_mse: 7.9938 - val_loss: 10.8364 - val_scaled_mse: 8.7261\n",
      "Epoch 113/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.1060 - scaled_mse: 7.9905 - val_loss: 10.8573 - val_scaled_mse: 8.7520\n",
      "Epoch 114/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.0955 - scaled_mse: 7.9802 - val_loss: 10.9433 - val_scaled_mse: 8.8264\n",
      "Epoch 115/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.1020 - scaled_mse: 7.9855 - val_loss: 10.9801 - val_scaled_mse: 8.8657\n",
      "Epoch 116/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.1002 - scaled_mse: 7.9807 - val_loss: 10.8975 - val_scaled_mse: 8.7690\n",
      "Epoch 117/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.0847 - scaled_mse: 7.9665 - val_loss: 10.8766 - val_scaled_mse: 8.7647\n",
      "Epoch 118/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.0917 - scaled_mse: 7.9730 - val_loss: 10.8770 - val_scaled_mse: 8.7851\n",
      "Epoch 119/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.0812 - scaled_mse: 7.9627 - val_loss: 10.7921 - val_scaled_mse: 8.6947\n",
      "Epoch 120/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.0755 - scaled_mse: 7.9541 - val_loss: 10.9085 - val_scaled_mse: 8.7912\n",
      "Epoch 121/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.0715 - scaled_mse: 7.9486 - val_loss: 10.9043 - val_scaled_mse: 8.7771\n",
      "Epoch 122/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.0684 - scaled_mse: 7.9434 - val_loss: 10.8248 - val_scaled_mse: 8.6977\n",
      "Epoch 123/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.0693 - scaled_mse: 7.9436 - val_loss: 10.9105 - val_scaled_mse: 8.7738\n",
      "Epoch 124/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.0633 - scaled_mse: 7.9381 - val_loss: 10.7979 - val_scaled_mse: 8.6571\n",
      "Epoch 125/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.0640 - scaled_mse: 7.9351 - val_loss: 10.8531 - val_scaled_mse: 8.6900\n",
      "Epoch 126/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.0649 - scaled_mse: 7.9371 - val_loss: 10.8410 - val_scaled_mse: 8.6817\n",
      "Epoch 127/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.0489 - scaled_mse: 7.9214 - val_loss: 10.8666 - val_scaled_mse: 8.7282\n",
      "Epoch 128/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.0578 - scaled_mse: 7.9294 - val_loss: 10.8497 - val_scaled_mse: 8.7019\n",
      "Epoch 129/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.0451 - scaled_mse: 7.9139 - val_loss: 10.8124 - val_scaled_mse: 8.6854\n",
      "Epoch 130/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.0563 - scaled_mse: 7.9235 - val_loss: 10.9342 - val_scaled_mse: 8.7554\n",
      "Epoch 131/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.0507 - scaled_mse: 7.9174 - val_loss: 10.8144 - val_scaled_mse: 8.6733\n",
      "Epoch 132/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.0391 - scaled_mse: 7.9041 - val_loss: 10.8330 - val_scaled_mse: 8.6785\n",
      "Epoch 133/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.0347 - scaled_mse: 7.9004 - val_loss: 10.8274 - val_scaled_mse: 8.7175\n",
      "Epoch 134/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.0331 - scaled_mse: 7.8964 - val_loss: 10.8029 - val_scaled_mse: 8.6649\n",
      "Epoch 135/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.0304 - scaled_mse: 7.8950 - val_loss: 10.8734 - val_scaled_mse: 8.7481\n",
      "Epoch 136/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.0307 - scaled_mse: 7.8971 - val_loss: 10.8040 - val_scaled_mse: 8.6573\n",
      "Epoch 137/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.0288 - scaled_mse: 7.8914 - val_loss: 10.8784 - val_scaled_mse: 8.7490\n",
      "Epoch 138/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.0172 - scaled_mse: 7.8793 - val_loss: 10.8380 - val_scaled_mse: 8.7038\n",
      "Epoch 139/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.0201 - scaled_mse: 7.8796 - val_loss: 10.8014 - val_scaled_mse: 8.6614\n",
      "Epoch 140/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.0191 - scaled_mse: 7.8774 - val_loss: 10.8098 - val_scaled_mse: 8.6805\n",
      "Epoch 141/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.0076 - scaled_mse: 7.8674 - val_loss: 10.7798 - val_scaled_mse: 8.6410\n",
      "Epoch 142/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.0185 - scaled_mse: 7.8772 - val_loss: 10.8041 - val_scaled_mse: 8.6300\n",
      "Epoch 143/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 10.0146 - scaled_mse: 7.8712 - val_loss: 10.7955 - val_scaled_mse: 8.6456\n",
      "Epoch 144/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9969 - scaled_mse: 7.8572 - val_loss: 10.8301 - val_scaled_mse: 8.6964\n",
      "Epoch 145/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 10.0071 - scaled_mse: 7.8608 - val_loss: 10.7841 - val_scaled_mse: 8.6144\n",
      "Epoch 146/300\n",
      "773/773 [==============================] - 21s 28ms/step - loss: 10.0031 - scaled_mse: 7.8582 - val_loss: 10.7948 - val_scaled_mse: 8.6521\n",
      "Epoch 147/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9926 - scaled_mse: 7.8486 - val_loss: 10.8441 - val_scaled_mse: 8.7140\n",
      "Epoch 148/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9964 - scaled_mse: 7.8486 - val_loss: 10.8036 - val_scaled_mse: 8.6387\n",
      "Epoch 149/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9926 - scaled_mse: 7.8463 - val_loss: 10.8250 - val_scaled_mse: 8.6957\n",
      "Epoch 150/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9945 - scaled_mse: 7.8469 - val_loss: 10.8028 - val_scaled_mse: 8.6484\n",
      "Epoch 151/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9843 - scaled_mse: 7.8362 - val_loss: 10.8629 - val_scaled_mse: 8.7221\n",
      "Epoch 152/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9892 - scaled_mse: 7.8407 - val_loss: 10.7446 - val_scaled_mse: 8.6366\n",
      "Epoch 153/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9787 - scaled_mse: 7.8321 - val_loss: 10.8055 - val_scaled_mse: 8.6410\n",
      "Epoch 154/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9859 - scaled_mse: 7.8343 - val_loss: 10.8359 - val_scaled_mse: 8.6990\n",
      "Epoch 155/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9810 - scaled_mse: 7.8317 - val_loss: 10.8152 - val_scaled_mse: 8.6595\n",
      "Epoch 156/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9845 - scaled_mse: 7.8340 - val_loss: 10.7654 - val_scaled_mse: 8.6458\n",
      "Epoch 157/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9746 - scaled_mse: 7.8220 - val_loss: 10.7885 - val_scaled_mse: 8.6531\n",
      "Epoch 158/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9741 - scaled_mse: 7.8210 - val_loss: 10.7448 - val_scaled_mse: 8.6242\n",
      "Epoch 159/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9768 - scaled_mse: 7.8231 - val_loss: 10.7586 - val_scaled_mse: 8.6234\n",
      "Epoch 160/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9678 - scaled_mse: 7.8145 - val_loss: 10.8333 - val_scaled_mse: 8.6612\n",
      "Epoch 161/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9672 - scaled_mse: 7.8131 - val_loss: 10.8334 - val_scaled_mse: 8.6733\n",
      "Epoch 162/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9677 - scaled_mse: 7.8124 - val_loss: 10.7837 - val_scaled_mse: 8.6333\n",
      "Epoch 163/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9621 - scaled_mse: 7.8099 - val_loss: 10.7788 - val_scaled_mse: 8.6173\n",
      "Epoch 164/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9621 - scaled_mse: 7.8038 - val_loss: 10.7831 - val_scaled_mse: 8.6418\n",
      "Epoch 165/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9574 - scaled_mse: 7.8008 - val_loss: 10.7580 - val_scaled_mse: 8.5998\n",
      "Epoch 166/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9571 - scaled_mse: 7.8018 - val_loss: 10.7770 - val_scaled_mse: 8.5879\n",
      "Epoch 167/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9546 - scaled_mse: 7.7957 - val_loss: 10.8414 - val_scaled_mse: 8.7103\n",
      "Epoch 168/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9554 - scaled_mse: 7.7974 - val_loss: 11.0056 - val_scaled_mse: 8.8781\n",
      "Epoch 169/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9556 - scaled_mse: 7.7966 - val_loss: 10.8092 - val_scaled_mse: 8.6356\n",
      "Epoch 170/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9487 - scaled_mse: 7.7883 - val_loss: 10.7467 - val_scaled_mse: 8.6162\n",
      "Epoch 171/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9484 - scaled_mse: 7.7905 - val_loss: 10.8360 - val_scaled_mse: 8.6713\n",
      "Epoch 172/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9441 - scaled_mse: 7.7834 - val_loss: 10.7845 - val_scaled_mse: 8.6179\n",
      "Epoch 173/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9437 - scaled_mse: 7.7855 - val_loss: 10.8246 - val_scaled_mse: 8.6670\n",
      "Epoch 174/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9352 - scaled_mse: 7.7771 - val_loss: 10.7720 - val_scaled_mse: 8.5991\n",
      "Epoch 175/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.9472 - scaled_mse: 7.7850 - val_loss: 10.7652 - val_scaled_mse: 8.6022\n",
      "Epoch 176/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.9425 - scaled_mse: 7.7837 - val_loss: 10.7708 - val_scaled_mse: 8.6067\n",
      "Epoch 177/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.9351 - scaled_mse: 7.7757 - val_loss: 10.8640 - val_scaled_mse: 8.6599\n",
      "Epoch 178/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9505 - scaled_mse: 7.7875 - val_loss: 10.8768 - val_scaled_mse: 8.6967\n",
      "Epoch 179/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9371 - scaled_mse: 7.7755 - val_loss: 10.7803 - val_scaled_mse: 8.6167\n",
      "Epoch 180/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9291 - scaled_mse: 7.7690 - val_loss: 10.7774 - val_scaled_mse: 8.6108\n",
      "Epoch 181/300\n",
      "773/773 [==============================] - 21s 28ms/step - loss: 9.9267 - scaled_mse: 7.7669 - val_loss: 10.8010 - val_scaled_mse: 8.6430\n",
      "Epoch 182/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9381 - scaled_mse: 7.7735 - val_loss: 10.8322 - val_scaled_mse: 8.6568\n",
      "Epoch 183/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9326 - scaled_mse: 7.7683 - val_loss: 10.7767 - val_scaled_mse: 8.6098\n",
      "Epoch 184/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9392 - scaled_mse: 7.7759 - val_loss: 10.7458 - val_scaled_mse: 8.5954\n",
      "Epoch 185/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9312 - scaled_mse: 7.7664 - val_loss: 10.7895 - val_scaled_mse: 8.6193\n",
      "Epoch 186/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9213 - scaled_mse: 7.7572 - val_loss: 10.8076 - val_scaled_mse: 8.6470\n",
      "Epoch 187/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9237 - scaled_mse: 7.7594 - val_loss: 10.7984 - val_scaled_mse: 8.6426\n",
      "Epoch 188/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.9196 - scaled_mse: 7.7577 - val_loss: 10.7922 - val_scaled_mse: 8.6368\n",
      "Epoch 189/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 9.9193 - scaled_mse: 7.7554 - val_loss: 10.7488 - val_scaled_mse: 8.6355\n",
      "Epoch 190/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.9200 - scaled_mse: 7.7567 - val_loss: 10.7937 - val_scaled_mse: 8.6084\n",
      "Epoch 191/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.9134 - scaled_mse: 7.7472 - val_loss: 10.7779 - val_scaled_mse: 8.5915\n",
      "Epoch 192/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.9230 - scaled_mse: 7.7576 - val_loss: 10.7357 - val_scaled_mse: 8.5748\n",
      "Epoch 193/300\n",
      "773/773 [==============================] - 23s 29ms/step - loss: 9.9182 - scaled_mse: 7.7517 - val_loss: 10.7369 - val_scaled_mse: 8.5729\n",
      "Epoch 194/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.9141 - scaled_mse: 7.7498 - val_loss: 10.7149 - val_scaled_mse: 8.5449\n",
      "Epoch 195/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 9.9089 - scaled_mse: 7.7388 - val_loss: 10.7505 - val_scaled_mse: 8.5876\n",
      "Epoch 196/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.9145 - scaled_mse: 7.7497 - val_loss: 10.8138 - val_scaled_mse: 8.6287\n",
      "Epoch 197/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 9.9185 - scaled_mse: 7.7508 - val_loss: 10.7352 - val_scaled_mse: 8.5763\n",
      "Epoch 198/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.9054 - scaled_mse: 7.7364 - val_loss: 10.7466 - val_scaled_mse: 8.5842\n",
      "Epoch 199/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 9.9072 - scaled_mse: 7.7388 - val_loss: 10.7272 - val_scaled_mse: 8.5698\n",
      "Epoch 200/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.9082 - scaled_mse: 7.7398 - val_loss: 10.7969 - val_scaled_mse: 8.6172\n",
      "Epoch 201/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.9095 - scaled_mse: 7.7411 - val_loss: 10.7919 - val_scaled_mse: 8.6016\n",
      "Epoch 202/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 9.9050 - scaled_mse: 7.7354 - val_loss: 10.7646 - val_scaled_mse: 8.5872\n",
      "Epoch 203/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.9084 - scaled_mse: 7.7369 - val_loss: 10.8862 - val_scaled_mse: 8.6855\n",
      "Epoch 204/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 9.9081 - scaled_mse: 7.7395 - val_loss: 10.7149 - val_scaled_mse: 8.5337\n",
      "Epoch 205/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 9.9037 - scaled_mse: 7.7363 - val_loss: 10.7505 - val_scaled_mse: 8.6204\n",
      "Epoch 206/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.9026 - scaled_mse: 7.7347 - val_loss: 10.8410 - val_scaled_mse: 8.6928\n",
      "Epoch 207/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 9.9013 - scaled_mse: 7.7321 - val_loss: 10.8749 - val_scaled_mse: 8.6894\n",
      "Epoch 208/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8974 - scaled_mse: 7.7290 - val_loss: 10.7709 - val_scaled_mse: 8.5830\n",
      "Epoch 209/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 9.9007 - scaled_mse: 7.7321 - val_loss: 10.7769 - val_scaled_mse: 8.5913\n",
      "Epoch 210/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 9.8905 - scaled_mse: 7.7220 - val_loss: 10.7473 - val_scaled_mse: 8.5762\n",
      "Epoch 211/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8917 - scaled_mse: 7.7203 - val_loss: 10.8150 - val_scaled_mse: 8.6345\n",
      "Epoch 212/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8954 - scaled_mse: 7.7253 - val_loss: 10.7490 - val_scaled_mse: 8.5844\n",
      "Epoch 213/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8883 - scaled_mse: 7.7193 - val_loss: 10.7142 - val_scaled_mse: 8.5729\n",
      "Epoch 214/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8951 - scaled_mse: 7.7243 - val_loss: 10.7889 - val_scaled_mse: 8.5934\n",
      "Epoch 215/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8851 - scaled_mse: 7.7141 - val_loss: 10.7587 - val_scaled_mse: 8.5773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 216/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8934 - scaled_mse: 7.7212 - val_loss: 10.7982 - val_scaled_mse: 8.6363\n",
      "Epoch 217/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8820 - scaled_mse: 7.7119 - val_loss: 10.7553 - val_scaled_mse: 8.5730\n",
      "Epoch 218/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8862 - scaled_mse: 7.7142 - val_loss: 10.8491 - val_scaled_mse: 8.6217\n",
      "Epoch 219/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8901 - scaled_mse: 7.7144 - val_loss: 10.7971 - val_scaled_mse: 8.5864\n",
      "Epoch 220/300\n",
      "773/773 [==============================] - 23s 29ms/step - loss: 9.8874 - scaled_mse: 7.7134 - val_loss: 10.7469 - val_scaled_mse: 8.5774\n",
      "Epoch 221/300\n",
      "773/773 [==============================] - 23s 29ms/step - loss: 9.8769 - scaled_mse: 7.7027 - val_loss: 10.7298 - val_scaled_mse: 8.5630\n",
      "Epoch 222/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8817 - scaled_mse: 7.7076 - val_loss: 10.7316 - val_scaled_mse: 8.5503\n",
      "Epoch 223/300\n",
      "773/773 [==============================] - 23s 29ms/step - loss: 9.8876 - scaled_mse: 7.7155 - val_loss: 10.7789 - val_scaled_mse: 8.5737\n",
      "Epoch 224/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8797 - scaled_mse: 7.7069 - val_loss: 10.7959 - val_scaled_mse: 8.5945\n",
      "Epoch 225/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8762 - scaled_mse: 7.7032 - val_loss: 10.7877 - val_scaled_mse: 8.5975\n",
      "Epoch 226/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8887 - scaled_mse: 7.7123 - val_loss: 10.7564 - val_scaled_mse: 8.5773\n",
      "Epoch 227/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8685 - scaled_mse: 7.6946 - val_loss: 10.7277 - val_scaled_mse: 8.5834\n",
      "Epoch 228/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8806 - scaled_mse: 7.7055 - val_loss: 10.9108 - val_scaled_mse: 8.7380\n",
      "Epoch 229/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8699 - scaled_mse: 7.6952 - val_loss: 10.7801 - val_scaled_mse: 8.5822\n",
      "Epoch 230/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8765 - scaled_mse: 7.7024 - val_loss: 10.7196 - val_scaled_mse: 8.5665\n",
      "Epoch 231/300\n",
      "773/773 [==============================] - 23s 29ms/step - loss: 9.8782 - scaled_mse: 7.7022 - val_loss: 10.7841 - val_scaled_mse: 8.5950\n",
      "Epoch 232/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8750 - scaled_mse: 7.6978 - val_loss: 10.7797 - val_scaled_mse: 8.5820\n",
      "Epoch 233/300\n",
      "773/773 [==============================] - 23s 30ms/step - loss: 9.8692 - scaled_mse: 7.6969 - val_loss: 10.7730 - val_scaled_mse: 8.5941\n",
      "Epoch 234/300\n",
      "773/773 [==============================] - 23s 29ms/step - loss: 9.8668 - scaled_mse: 7.6928 - val_loss: 10.8322 - val_scaled_mse: 8.6819\n",
      "Epoch 235/300\n",
      "773/773 [==============================] - 23s 29ms/step - loss: 9.8783 - scaled_mse: 7.6995 - val_loss: 10.7556 - val_scaled_mse: 8.5896\n",
      "Epoch 236/300\n",
      "773/773 [==============================] - 23s 30ms/step - loss: 9.8685 - scaled_mse: 7.6926 - val_loss: 10.7388 - val_scaled_mse: 8.5712\n",
      "Epoch 237/300\n",
      "773/773 [==============================] - 23s 30ms/step - loss: 9.8699 - scaled_mse: 7.6931 - val_loss: 10.7408 - val_scaled_mse: 8.5630\n",
      "Epoch 238/300\n",
      "773/773 [==============================] - 23s 29ms/step - loss: 9.8693 - scaled_mse: 7.6928 - val_loss: 10.7497 - val_scaled_mse: 8.5858\n",
      "Epoch 239/300\n",
      "773/773 [==============================] - 23s 29ms/step - loss: 9.8574 - scaled_mse: 7.6824 - val_loss: 10.7645 - val_scaled_mse: 8.5996\n",
      "Epoch 240/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8650 - scaled_mse: 7.6893 - val_loss: 10.8112 - val_scaled_mse: 8.6234\n",
      "Epoch 241/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8640 - scaled_mse: 7.6873 - val_loss: 10.7194 - val_scaled_mse: 8.5922\n",
      "Epoch 242/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8622 - scaled_mse: 7.6866 - val_loss: 10.7244 - val_scaled_mse: 8.5685\n",
      "Epoch 243/300\n",
      "773/773 [==============================] - 23s 29ms/step - loss: 9.8706 - scaled_mse: 7.6895 - val_loss: 10.7576 - val_scaled_mse: 8.5675\n",
      "Epoch 244/300\n",
      "773/773 [==============================] - 23s 29ms/step - loss: 9.8603 - scaled_mse: 7.6811 - val_loss: 10.7224 - val_scaled_mse: 8.5730\n",
      "Epoch 245/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8496 - scaled_mse: 7.6721 - val_loss: 10.7899 - val_scaled_mse: 8.5756\n",
      "Epoch 246/300\n",
      "773/773 [==============================] - 23s 30ms/step - loss: 9.8524 - scaled_mse: 7.6749 - val_loss: 10.7266 - val_scaled_mse: 8.5293\n",
      "Epoch 247/300\n",
      "773/773 [==============================] - 23s 30ms/step - loss: 9.8562 - scaled_mse: 7.6772 - val_loss: 10.7763 - val_scaled_mse: 8.5894\n",
      "Epoch 248/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8617 - scaled_mse: 7.6828 - val_loss: 10.7695 - val_scaled_mse: 8.6004\n",
      "Epoch 249/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8554 - scaled_mse: 7.6722 - val_loss: 10.8554 - val_scaled_mse: 8.6459\n",
      "Epoch 250/300\n",
      "773/773 [==============================] - 23s 29ms/step - loss: 9.8572 - scaled_mse: 7.6727 - val_loss: 10.7742 - val_scaled_mse: 8.5734\n",
      "Epoch 251/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8504 - scaled_mse: 7.6715 - val_loss: 10.7173 - val_scaled_mse: 8.5883\n",
      "Epoch 252/300\n",
      "773/773 [==============================] - 23s 29ms/step - loss: 9.8548 - scaled_mse: 7.6765 - val_loss: 10.7316 - val_scaled_mse: 8.5578\n",
      "Epoch 253/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 9.8472 - scaled_mse: 7.6681 - val_loss: 10.7483 - val_scaled_mse: 8.5486\n",
      "Epoch 254/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8515 - scaled_mse: 7.6675 - val_loss: 10.7214 - val_scaled_mse: 8.5648\n",
      "Epoch 255/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8480 - scaled_mse: 7.6681 - val_loss: 10.7257 - val_scaled_mse: 8.5249\n",
      "Epoch 256/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 9.8574 - scaled_mse: 7.6775 - val_loss: 10.7591 - val_scaled_mse: 8.5717\n",
      "Epoch 257/300\n",
      "773/773 [==============================] - 23s 30ms/step - loss: 9.8479 - scaled_mse: 7.6643 - val_loss: 10.7208 - val_scaled_mse: 8.5708\n",
      "Epoch 258/300\n",
      "773/773 [==============================] - 23s 29ms/step - loss: 9.8496 - scaled_mse: 7.6668 - val_loss: 10.7388 - val_scaled_mse: 8.5580\n",
      "Epoch 259/300\n",
      "773/773 [==============================] - 23s 29ms/step - loss: 9.8441 - scaled_mse: 7.6634 - val_loss: 10.7137 - val_scaled_mse: 8.5383\n",
      "Epoch 260/300\n",
      "773/773 [==============================] - 23s 29ms/step - loss: 9.8441 - scaled_mse: 7.6595 - val_loss: 10.7620 - val_scaled_mse: 8.5821\n",
      "Epoch 261/300\n",
      "773/773 [==============================] - 23s 29ms/step - loss: 9.8485 - scaled_mse: 7.6666 - val_loss: 10.7248 - val_scaled_mse: 8.5309\n",
      "Epoch 262/300\n",
      "773/773 [==============================] - 23s 30ms/step - loss: 9.8470 - scaled_mse: 7.6643 - val_loss: 10.7302 - val_scaled_mse: 8.5183\n",
      "Epoch 263/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8431 - scaled_mse: 7.6595 - val_loss: 10.7519 - val_scaled_mse: 8.5420\n",
      "Epoch 264/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8522 - scaled_mse: 7.6666 - val_loss: 10.7323 - val_scaled_mse: 8.5511\n",
      "Epoch 265/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8377 - scaled_mse: 7.6532 - val_loss: 10.7214 - val_scaled_mse: 8.5545\n",
      "Epoch 266/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 9.8330 - scaled_mse: 7.6504 - val_loss: 10.8497 - val_scaled_mse: 8.6776\n",
      "Epoch 267/300\n",
      "773/773 [==============================] - 23s 30ms/step - loss: 9.8458 - scaled_mse: 7.6595 - val_loss: 10.7530 - val_scaled_mse: 8.5600\n",
      "Epoch 268/300\n",
      "773/773 [==============================] - 23s 30ms/step - loss: 9.8368 - scaled_mse: 7.6542 - val_loss: 10.7254 - val_scaled_mse: 8.5461\n",
      "Epoch 269/300\n",
      "773/773 [==============================] - 23s 30ms/step - loss: 9.8350 - scaled_mse: 7.6518 - val_loss: 10.8442 - val_scaled_mse: 8.6701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 270/300\n",
      "773/773 [==============================] - 23s 29ms/step - loss: 9.8407 - scaled_mse: 7.6550 - val_loss: 10.7117 - val_scaled_mse: 8.5271\n",
      "Epoch 271/300\n",
      "773/773 [==============================] - 23s 29ms/step - loss: 9.8405 - scaled_mse: 7.6589 - val_loss: 10.7246 - val_scaled_mse: 8.5132\n",
      "Epoch 272/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8310 - scaled_mse: 7.6472 - val_loss: 10.7493 - val_scaled_mse: 8.5734\n",
      "Epoch 273/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8392 - scaled_mse: 7.6550 - val_loss: 10.7438 - val_scaled_mse: 8.5209\n",
      "Epoch 274/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8289 - scaled_mse: 7.6451 - val_loss: 10.7822 - val_scaled_mse: 8.6348\n",
      "Epoch 275/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8375 - scaled_mse: 7.6521 - val_loss: 10.7339 - val_scaled_mse: 8.5421\n",
      "Epoch 276/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 9.8292 - scaled_mse: 7.6454 - val_loss: 10.8639 - val_scaled_mse: 8.6536\n",
      "Epoch 277/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 9.8316 - scaled_mse: 7.6440 - val_loss: 10.7269 - val_scaled_mse: 8.5551\n",
      "Epoch 278/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8324 - scaled_mse: 7.6459 - val_loss: 10.7566 - val_scaled_mse: 8.5723\n",
      "Epoch 279/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8334 - scaled_mse: 7.6469 - val_loss: 10.7420 - val_scaled_mse: 8.5657\n",
      "Epoch 280/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 9.8366 - scaled_mse: 7.6527 - val_loss: 10.8670 - val_scaled_mse: 8.6836\n",
      "Epoch 281/300\n",
      "773/773 [==============================] - 21s 28ms/step - loss: 9.8320 - scaled_mse: 7.6427 - val_loss: 10.7773 - val_scaled_mse: 8.6172\n",
      "Epoch 282/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8223 - scaled_mse: 7.6363 - val_loss: 10.7231 - val_scaled_mse: 8.5521\n",
      "Epoch 283/300\n",
      "773/773 [==============================] - 22s 29ms/step - loss: 9.8238 - scaled_mse: 7.6377 - val_loss: 10.7287 - val_scaled_mse: 8.5136\n",
      "Epoch 284/300\n",
      "773/773 [==============================] - 23s 30ms/step - loss: 9.8333 - scaled_mse: 7.6450 - val_loss: 10.7319 - val_scaled_mse: 8.5645\n",
      "Epoch 285/300\n",
      "773/773 [==============================] - 23s 29ms/step - loss: 9.8282 - scaled_mse: 7.6429 - val_loss: 10.7222 - val_scaled_mse: 8.5287\n",
      "Epoch 286/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.8303 - scaled_mse: 7.6433 - val_loss: 10.7603 - val_scaled_mse: 8.5886\n",
      "Epoch 287/300\n",
      "773/773 [==============================] - 23s 30ms/step - loss: 9.8187 - scaled_mse: 7.6316 - val_loss: 10.7343 - val_scaled_mse: 8.5363\n",
      "Epoch 288/300\n",
      "773/773 [==============================] - 23s 30ms/step - loss: 9.8324 - scaled_mse: 7.6440 - val_loss: 10.8148 - val_scaled_mse: 8.5894\n",
      "Epoch 289/300\n",
      "773/773 [==============================] - 23s 29ms/step - loss: 9.8272 - scaled_mse: 7.6392 - val_loss: 10.7067 - val_scaled_mse: 8.5142\n",
      "Epoch 290/300\n",
      "773/773 [==============================] - 23s 29ms/step - loss: 9.8209 - scaled_mse: 7.6350 - val_loss: 10.7207 - val_scaled_mse: 8.5482\n",
      "Epoch 291/300\n",
      "773/773 [==============================] - 21s 28ms/step - loss: 9.8242 - scaled_mse: 7.6377 - val_loss: 10.7018 - val_scaled_mse: 8.5299\n",
      "Epoch 292/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 9.8195 - scaled_mse: 7.6313 - val_loss: 10.6941 - val_scaled_mse: 8.5312\n",
      "Epoch 293/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 9.8247 - scaled_mse: 7.6347 - val_loss: 10.7115 - val_scaled_mse: 8.5227\n",
      "Epoch 294/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.8244 - scaled_mse: 7.6362 - val_loss: 10.7253 - val_scaled_mse: 8.5108\n",
      "Epoch 295/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.8212 - scaled_mse: 7.6341 - val_loss: 10.7125 - val_scaled_mse: 8.5350\n",
      "Epoch 296/300\n",
      "773/773 [==============================] - 21s 28ms/step - loss: 9.8184 - scaled_mse: 7.6298 - val_loss: 10.6967 - val_scaled_mse: 8.5178\n",
      "Epoch 297/300\n",
      "773/773 [==============================] - 21s 28ms/step - loss: 9.8199 - scaled_mse: 7.6316 - val_loss: 10.7655 - val_scaled_mse: 8.5346\n",
      "Epoch 298/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 9.8218 - scaled_mse: 7.6327 - val_loss: 10.7275 - val_scaled_mse: 8.5492\n",
      "Epoch 299/300\n",
      "773/773 [==============================] - 21s 27ms/step - loss: 9.8206 - scaled_mse: 7.6317 - val_loss: 10.7523 - val_scaled_mse: 8.5338\n",
      "Epoch 300/300\n",
      "773/773 [==============================] - 22s 28ms/step - loss: 9.8110 - scaled_mse: 7.6225 - val_loss: 10.7659 - val_scaled_mse: 8.5411\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f81882f22e0>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beta_vae.fit(train_generator, validation_data=val_generator, epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
